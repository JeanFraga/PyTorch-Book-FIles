{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BrLt-C4PRV_f",
    "outputId": "93b5119e-505d-4ab5-a3bb-26803d9b517f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Metal (MPS) Acceleration Test ===\n",
      "MPS Available: True\n",
      "MPS Built: True\n",
      "Using device: mps\n",
      "Tensor operation on MPS successful!\n",
      "x: tensor([1., 2., 3.], device='mps:0')\n",
      "y: tensor([4., 5., 6.], device='mps:0')\n",
      "x + y: tensor([5., 7., 9.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# Quick Metal (MPS) test\n",
    "import torch\n",
    "\n",
    "print(\"=== Metal (MPS) Acceleration Test ===\")\n",
    "print(f\"MPS Available: {torch.backends.mps.is_available()}\")\n",
    "print(f\"MPS Built: {torch.backends.mps.is_built()}\")\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Create a simple tensor operation on MPS\n",
    "    x = torch.tensor([1.0, 2.0, 3.0], device=device)\n",
    "    y = torch.tensor([4.0, 5.0, 6.0], device=device)\n",
    "    result = x + y\n",
    "    \n",
    "    print(f\"Tensor operation on MPS successful!\")\n",
    "    print(f\"x: {x}\")\n",
    "    print(f\"y: {y}\")\n",
    "    print(f\"x + y: {result}\")\n",
    "else:\n",
    "    print(\"MPS not available - using CPU\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "It4yTLaRao7o",
    "outputId": "896ad986-b4bd-4376-ef3d-9575aa9cd807"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 14.942179679870605\n",
      "Loss = 11.974388122558594\n",
      "Loss = 9.634984970092773\n",
      "Loss = 7.7900567054748535\n",
      "Loss = 6.334249496459961\n",
      "Loss = 5.1846699714660645\n",
      "Loss = 4.27610445022583\n",
      "Loss = 3.557241439819336\n",
      "Loss = 2.9877102375030518\n",
      "Loss = 2.5357470512390137\n",
      "Loss = 2.176360845565796\n",
      "Loss = 1.8898884057998657\n",
      "Loss = 1.66085684299469\n",
      "Loss = 1.4770923852920532\n",
      "Loss = 1.3290150165557861\n",
      "Loss = 1.2090859413146973\n",
      "Loss = 1.111374020576477\n",
      "Loss = 1.0312098264694214\n",
      "Loss = 0.9649191498756409\n",
      "Loss = 0.9096093773841858\n",
      "Loss = 0.8630037307739258\n",
      "Loss = 0.8233097195625305\n",
      "Loss = 0.7891157269477844\n",
      "Loss = 0.7593095302581787\n",
      "Loss = 0.733015239238739\n",
      "Loss = 0.7095420360565186\n",
      "Loss = 0.6883460879325867\n",
      "Loss = 0.6689973473548889\n",
      "Loss = 0.6511570811271667\n",
      "Loss = 0.6345572471618652\n",
      "Loss = 0.6189860701560974\n",
      "Loss = 0.6042757630348206\n",
      "Loss = 0.5902932286262512\n",
      "Loss = 0.5769327878952026\n",
      "Loss = 0.5641102194786072\n",
      "Loss = 0.551758348941803\n",
      "Loss = 0.5398232936859131\n",
      "Loss = 0.5282615423202515\n",
      "Loss = 0.5170383453369141\n",
      "Loss = 0.5061250329017639\n",
      "Loss = 0.4954984486103058\n",
      "Loss = 0.48513922095298767\n",
      "Loss = 0.4750315248966217\n",
      "Loss = 0.46516188979148865\n",
      "Loss = 0.4555189311504364\n",
      "Loss = 0.4460926949977875\n",
      "Loss = 0.43687498569488525\n",
      "Loss = 0.4278583526611328\n",
      "Loss = 0.41903600096702576\n",
      "Loss = 0.4104021489620209\n",
      "Loss = 0.40195128321647644\n",
      "Loss = 0.3936785161495209\n",
      "Loss = 0.38557910919189453\n",
      "Loss = 0.3776489496231079\n",
      "Loss = 0.36988377571105957\n",
      "Loss = 0.3622798025608063\n",
      "Loss = 0.35483336448669434\n",
      "Loss = 0.3475409746170044\n",
      "Loss = 0.34039923548698425\n",
      "Loss = 0.3334047794342041\n",
      "Loss = 0.3265545070171356\n",
      "Loss = 0.31984543800354004\n",
      "Loss = 0.31327441334724426\n",
      "Loss = 0.30683863162994385\n",
      "Loss = 0.3005352020263672\n",
      "Loss = 0.29436150193214417\n",
      "Loss = 0.28831470012664795\n",
      "Loss = 0.2823922038078308\n",
      "Loss = 0.27659139037132263\n",
      "Loss = 0.2709098756313324\n",
      "Loss = 0.2653450071811676\n",
      "Loss = 0.25989454984664917\n",
      "Loss = 0.2545560300350189\n",
      "Loss = 0.2493271827697754\n",
      "Loss = 0.2442057877779007\n",
      "Loss = 0.23918962478637695\n",
      "Loss = 0.23427651822566986\n",
      "Loss = 0.22946427762508392\n",
      "Loss = 0.22475093603134155\n",
      "Loss = 0.22013439238071442\n",
      "Loss = 0.21561264991760254\n",
      "Loss = 0.21118386089801788\n",
      "Loss = 0.2068459838628769\n",
      "Loss = 0.2025972455739975\n",
      "Loss = 0.19843576848506927\n",
      "Loss = 0.19435973465442657\n",
      "Loss = 0.19036753475666046\n",
      "Loss = 0.18645723164081573\n",
      "Loss = 0.18262727558612823\n",
      "Loss = 0.17887602746486664\n",
      "Loss = 0.17520175874233246\n",
      "Loss = 0.1716030389070511\n",
      "Loss = 0.1680782288312912\n",
      "Loss = 0.16462579369544983\n",
      "Loss = 0.1612442433834076\n",
      "Loss = 0.15793216228485107\n",
      "Loss = 0.15468811988830566\n",
      "Loss = 0.15151077508926392\n",
      "Loss = 0.14839865267276764\n",
      "Loss = 0.1453504115343094\n",
      "Loss = 0.14236481487751007\n",
      "Loss = 0.1394406110048294\n",
      "Loss = 0.13657639920711517\n",
      "Loss = 0.13377100229263306\n",
      "Loss = 0.13102328777313232\n",
      "Loss = 0.1283319741487503\n",
      "Loss = 0.12569600343704224\n",
      "Loss = 0.12311410903930664\n",
      "Loss = 0.12058524042367935\n",
      "Loss = 0.11810839921236038\n",
      "Loss = 0.11568234115839005\n",
      "Loss = 0.11330617219209671\n",
      "Loss = 0.11097878217697144\n",
      "Loss = 0.10869917273521423\n",
      "Loss = 0.10646649450063705\n",
      "Loss = 0.1042795479297638\n",
      "Loss = 0.10213757306337357\n",
      "Loss = 0.10003963857889175\n",
      "Loss = 0.09798476845026016\n",
      "Loss = 0.09597209841012955\n",
      "Loss = 0.09400079399347305\n",
      "Loss = 0.09206997603178024\n",
      "Loss = 0.09017875790596008\n",
      "Loss = 0.08832646161317825\n",
      "Loss = 0.08651220053434372\n",
      "Loss = 0.08473518490791321\n",
      "Loss = 0.08299467712640762\n",
      "Loss = 0.08128989487886429\n",
      "Loss = 0.07962017506361008\n",
      "Loss = 0.07798469811677933\n",
      "Loss = 0.07638286799192429\n",
      "Loss = 0.07481388747692108\n",
      "Loss = 0.07327719777822495\n",
      "Loss = 0.07177204638719559\n",
      "Loss = 0.07029780000448227\n",
      "Loss = 0.06885379552841187\n",
      "Loss = 0.06743951886892319\n",
      "Loss = 0.06605429202318192\n",
      "Loss = 0.06469747424125671\n",
      "Loss = 0.06336856633424759\n",
      "Loss = 0.06206691265106201\n",
      "Loss = 0.06079202517867088\n",
      "Loss = 0.05954331159591675\n",
      "Loss = 0.0583202950656414\n",
      "Loss = 0.0571223646402359\n",
      "Loss = 0.05594902113080025\n",
      "Loss = 0.054799821227788925\n",
      "Loss = 0.05367419496178627\n",
      "Loss = 0.052571699023246765\n",
      "Loss = 0.05149184167385101\n",
      "Loss = 0.050434160977602005\n",
      "Loss = 0.04939822852611542\n",
      "Loss = 0.04838353767991066\n",
      "Loss = 0.047389719635248184\n",
      "Loss = 0.04641631618142128\n",
      "Loss = 0.045462917536497116\n",
      "Loss = 0.044529035687446594\n",
      "Loss = 0.043614406138658524\n",
      "Loss = 0.04271852970123291\n",
      "Loss = 0.0418410561978817\n",
      "Loss = 0.040981631726026535\n",
      "Loss = 0.04013984277844429\n",
      "Loss = 0.03931532800197601\n",
      "Loss = 0.038507770746946335\n",
      "Loss = 0.03771677240729332\n",
      "Loss = 0.03694206476211548\n",
      "Loss = 0.03618326038122177\n",
      "Loss = 0.035440023988485336\n",
      "Loss = 0.03471206873655319\n",
      "Loss = 0.03399905189871788\n",
      "Loss = 0.03330070525407791\n",
      "Loss = 0.03261667117476463\n",
      "Loss = 0.031946707516908646\n",
      "Loss = 0.031290534883737564\n",
      "Loss = 0.030647793784737587\n",
      "Loss = 0.030018290504813194\n",
      "Loss = 0.02940170280635357\n",
      "Loss = 0.028797760605812073\n",
      "Loss = 0.028206216171383858\n",
      "Loss = 0.027626851573586464\n",
      "Loss = 0.02705940417945385\n",
      "Loss = 0.026503583416342735\n",
      "Loss = 0.025959176942706108\n",
      "Loss = 0.02542594075202942\n",
      "Loss = 0.02490367740392685\n",
      "Loss = 0.024392150342464447\n",
      "Loss = 0.023891113698482513\n",
      "Loss = 0.023400386795401573\n",
      "Loss = 0.022919731214642525\n",
      "Loss = 0.022448940202593803\n",
      "Loss = 0.02198782004415989\n",
      "Loss = 0.02153617888689041\n",
      "Loss = 0.021093817427754402\n",
      "Loss = 0.020660536363720894\n",
      "Loss = 0.020236149430274963\n",
      "Loss = 0.019820498302578926\n",
      "Loss = 0.019413365051150322\n",
      "Loss = 0.019014615565538406\n",
      "Loss = 0.018624024465680122\n",
      "Loss = 0.01824146881699562\n",
      "Loss = 0.017866773530840874\n",
      "Loss = 0.0174997728317976\n",
      "Loss = 0.017140323296189308\n",
      "Loss = 0.016788257285952568\n",
      "Loss = 0.016443414613604546\n",
      "Loss = 0.01610565185546875\n",
      "Loss = 0.015774840489029884\n",
      "Loss = 0.015450806356966496\n",
      "Loss = 0.015133445151150227\n",
      "Loss = 0.014822572469711304\n",
      "Loss = 0.014518119394779205\n",
      "Loss = 0.014219898730516434\n",
      "Loss = 0.013927832245826721\n",
      "Loss = 0.013641743920743465\n",
      "Loss = 0.013361538760364056\n",
      "Loss = 0.013087074272334576\n",
      "Loss = 0.01281826850026846\n",
      "Loss = 0.012554962188005447\n",
      "Loss = 0.012297078035771847\n",
      "Loss = 0.012044490315020084\n",
      "Loss = 0.011797093786299229\n",
      "Loss = 0.011554762721061707\n",
      "Loss = 0.011317424476146698\n",
      "Loss = 0.011084959842264652\n",
      "Loss = 0.010857273824512959\n",
      "Loss = 0.010634244419634342\n",
      "Loss = 0.010415812022984028\n",
      "Loss = 0.010201863013207912\n",
      "Loss = 0.009992304258048534\n",
      "Loss = 0.009787057526409626\n",
      "Loss = 0.009586026892066002\n",
      "Loss = 0.009389127604663372\n",
      "Loss = 0.009196257218718529\n",
      "Loss = 0.009007378481328487\n",
      "Loss = 0.008822349831461906\n",
      "Loss = 0.008641136810183525\n",
      "Loss = 0.008463638834655285\n",
      "Loss = 0.008289795368909836\n",
      "Loss = 0.008119512349367142\n",
      "Loss = 0.007952742278575897\n",
      "Loss = 0.007789393421262503\n",
      "Loss = 0.007629393134266138\n",
      "Loss = 0.007472682744264603\n",
      "Loss = 0.007319189142435789\n",
      "Loss = 0.007168848067522049\n",
      "Loss = 0.0070215812884271145\n",
      "Loss = 0.006877364125102758\n",
      "Loss = 0.00673609459772706\n",
      "Loss = 0.006597734522074461\n",
      "Loss = 0.006462210323661566\n",
      "Loss = 0.006329474505037069\n",
      "Loss = 0.006199465598911047\n",
      "Loss = 0.006072124466300011\n",
      "Loss = 0.005947405006736517\n",
      "Loss = 0.005825227126479149\n",
      "Loss = 0.005705586168915033\n",
      "Loss = 0.005588393658399582\n",
      "Loss = 0.005473592784255743\n",
      "Loss = 0.00536116398870945\n",
      "Loss = 0.0052510458044707775\n",
      "Loss = 0.005143183283507824\n",
      "Loss = 0.005037548486143351\n",
      "Loss = 0.004934078082442284\n",
      "Loss = 0.0048327213153243065\n",
      "Loss = 0.004733460955321789\n",
      "Loss = 0.004636233672499657\n",
      "Loss = 0.004540995229035616\n",
      "Loss = 0.004447717219591141\n",
      "Loss = 0.004356364253908396\n",
      "Loss = 0.004266880918294191\n",
      "Loss = 0.004179237876087427\n",
      "Loss = 0.004093395080417395\n",
      "Loss = 0.0040093217976391315\n",
      "Loss = 0.0039269584231078625\n",
      "Loss = 0.0038462921511381865\n",
      "Loss = 0.003767296439036727\n",
      "Loss = 0.0036899156402796507\n",
      "Loss = 0.0036141115706413984\n",
      "Loss = 0.003539883764460683\n",
      "Loss = 0.0034671647008508444\n",
      "Loss = 0.0033959464635699987\n",
      "Loss = 0.003326197387650609\n",
      "Loss = 0.003257876029238105\n",
      "Loss = 0.0031909553799778223\n",
      "Loss = 0.0031254140194505453\n",
      "Loss = 0.003061206778511405\n",
      "Loss = 0.0029983369167894125\n",
      "Loss = 0.002936747157946229\n",
      "Loss = 0.0028764279559254646\n",
      "Loss = 0.002817348809912801\n",
      "Loss = 0.002759471768513322\n",
      "Loss = 0.002702790079638362\n",
      "Loss = 0.0026472716126590967\n",
      "Loss = 0.0025928982067853212\n",
      "Loss = 0.0025396342389285564\n",
      "Loss = 0.0024874720256775618\n",
      "Loss = 0.002436379436403513\n",
      "Loss = 0.0023863394744694233\n",
      "Loss = 0.002337320940569043\n",
      "Loss = 0.0022893052082508802\n",
      "Loss = 0.0022422843612730503\n",
      "Loss = 0.0021962281316518784\n",
      "Loss = 0.002151117194443941\n",
      "Loss = 0.002106930362060666\n",
      "Loss = 0.0020636587869375944\n",
      "Loss = 0.002021262887865305\n",
      "Loss = 0.001979749882593751\n",
      "Loss = 0.0019390786765143275\n",
      "Loss = 0.001899250433780253\n",
      "Loss = 0.0018602394266054034\n",
      "Loss = 0.0018220273777842522\n",
      "Loss = 0.0017846021801233292\n",
      "Loss = 0.0017479523085057735\n",
      "Loss = 0.0017120451666414738\n",
      "Loss = 0.0016768835484981537\n",
      "Loss = 0.001642436720430851\n",
      "Loss = 0.0016087029362097383\n",
      "Loss = 0.0015756565844640136\n",
      "Loss = 0.0015432952204719186\n",
      "Loss = 0.001511596143245697\n",
      "Loss = 0.0014805429382249713\n",
      "Loss = 0.001450132578611374\n",
      "Loss = 0.0014203493483364582\n",
      "Loss = 0.0013911756686866283\n",
      "Loss = 0.0013625927967950702\n",
      "Loss = 0.0013346074847504497\n",
      "Loss = 0.0013071949360892177\n",
      "Loss = 0.0012803454883396626\n",
      "Loss = 0.0012540403986349702\n",
      "Loss = 0.00122828281018883\n",
      "Loss = 0.0012030525831505656\n",
      "Loss = 0.0011783397058025002\n",
      "Loss = 0.0011541364947333932\n",
      "Loss = 0.0011304315412417054\n",
      "Loss = 0.0011072143679484725\n",
      "Loss = 0.0010844748467206955\n",
      "Loss = 0.0010621928377076983\n",
      "Loss = 0.0010403768392279744\n",
      "Loss = 0.0010190053144469857\n",
      "Loss = 0.0009980767499655485\n",
      "Loss = 0.0009775733342394233\n",
      "Loss = 0.0009574931464157999\n",
      "Loss = 0.0009378288523294032\n",
      "Loss = 0.0009185662493109703\n",
      "Loss = 0.0008996972464956343\n",
      "Loss = 0.0008812146261334419\n",
      "Loss = 0.0008631183882243931\n",
      "Loss = 0.0008453868795186281\n",
      "Loss = 0.0008280212059617043\n",
      "Loss = 0.0008110169437713921\n",
      "Loss = 0.0007943555247038603\n",
      "Loss = 0.0007780389860272408\n",
      "Loss = 0.0007620570249855518\n",
      "Loss = 0.0007464045193046331\n",
      "Loss = 0.0007310723303817213\n",
      "Loss = 0.0007160556851886213\n",
      "Loss = 0.000701352022588253\n",
      "Loss = 0.0006869420758448541\n",
      "Loss = 0.0006728321313858032\n",
      "Loss = 0.0006590125267393887\n",
      "Loss = 0.0006454763934016228\n",
      "Loss = 0.0006322204135358334\n",
      "Loss = 0.0006192316068336368\n",
      "Loss = 0.0006065152701921761\n",
      "Loss = 0.0005940584815107286\n",
      "Loss = 0.0005818560603074729\n",
      "Loss = 0.0005699030589312315\n",
      "Loss = 0.0005582000012509525\n",
      "Loss = 0.0005467318114824593\n",
      "Loss = 0.0005355039029382169\n",
      "Loss = 0.0005245018983259797\n",
      "Loss = 0.0005137304542586207\n",
      "Loss = 0.0005031805485486984\n",
      "Loss = 0.0004928435082547367\n",
      "Loss = 0.0004827210505027324\n",
      "Loss = 0.0004728035710286349\n",
      "Loss = 0.00046309048775583506\n",
      "Loss = 0.00045358052011579275\n",
      "Loss = 0.000444265577243641\n",
      "Loss = 0.0004351373063400388\n",
      "Loss = 0.0004261997528374195\n",
      "Loss = 0.00041744697955437005\n",
      "Loss = 0.00040887168142944574\n",
      "Loss = 0.0004004718502983451\n",
      "Loss = 0.00039224582724273205\n",
      "Loss = 0.0003841907891910523\n",
      "Loss = 0.00037629876169376075\n",
      "Loss = 0.0003685679694171995\n",
      "Loss = 0.00036099902354180813\n",
      "Loss = 0.00035358406603336334\n",
      "Loss = 0.00034632053575478494\n",
      "Loss = 0.00033920499845407903\n",
      "Loss = 0.00033223850186914206\n",
      "Loss = 0.00032541248947381973\n",
      "Loss = 0.00031873048283159733\n",
      "Loss = 0.00031218150979839265\n",
      "Loss = 0.00030576938297599554\n",
      "Loss = 0.000299490406177938\n",
      "Loss = 0.0002933375653810799\n",
      "Loss = 0.0002873105404432863\n",
      "Loss = 0.00028141067014075816\n",
      "Loss = 0.0002756294852588326\n",
      "Loss = 0.00026996867381967604\n",
      "Loss = 0.00026442136731930077\n",
      "Loss = 0.00025898960302583873\n",
      "Loss = 0.00025366933550685644\n",
      "Loss = 0.00024845931329764426\n",
      "Loss = 0.00024335824127774686\n",
      "Loss = 0.00023836031323298812\n",
      "Loss = 0.00023346250236500055\n",
      "Loss = 0.00022866908693686128\n",
      "Loss = 0.00022397033171728253\n",
      "Loss = 0.0002193708933191374\n",
      "Loss = 0.00021486343757715076\n",
      "Loss = 0.00021045234461780638\n",
      "Loss = 0.00020612833031918854\n",
      "Loss = 0.00020189497445244342\n",
      "Loss = 0.00019774731481447816\n",
      "Loss = 0.0001936874323291704\n",
      "Loss = 0.00018970889504998922\n",
      "Loss = 0.00018581199401523918\n",
      "Loss = 0.00018199584155809134\n",
      "Loss = 0.0001782586332410574\n",
      "Loss = 0.00017459587252233177\n",
      "Loss = 0.00017100822879001498\n",
      "Loss = 0.00016749667702242732\n",
      "Loss = 0.00016405795759055763\n",
      "Loss = 0.0001606866717338562\n",
      "Loss = 0.00015738779620733112\n",
      "Loss = 0.00015415376401506364\n",
      "Loss = 0.0001509865978732705\n",
      "Loss = 0.00014788670523557812\n",
      "Loss = 0.00014484919665846974\n",
      "Loss = 0.0001418749161530286\n",
      "Loss = 0.00013895906158722937\n",
      "Loss = 0.0001361051108688116\n",
      "Loss = 0.0001333094696747139\n",
      "Loss = 0.00013057120668236166\n",
      "Loss = 0.00012788872118107975\n",
      "Loss = 0.0001252608490176499\n",
      "Loss = 0.0001226877939188853\n",
      "Loss = 0.00012016884284093976\n",
      "Loss = 0.00011769944103434682\n",
      "Loss = 0.00011528164759511128\n",
      "Loss = 0.0001129147713072598\n",
      "Loss = 0.00011059589451178908\n",
      "Loss = 0.00010832382395165041\n",
      "Loss = 0.00010609960736474022\n",
      "Loss = 0.00010391965042799711\n",
      "Loss = 0.0001017848335322924\n",
      "Loss = 9.969485836336389e-05\n",
      "Loss = 9.76466981228441e-05\n",
      "Loss = 9.564016363583505e-05\n",
      "Loss = 9.367510210722685e-05\n",
      "Loss = 9.175153536489233e-05\n",
      "Loss = 8.986579632619396e-05\n",
      "Loss = 8.802063530310988e-05\n",
      "Loss = 8.621211600257084e-05\n",
      "Loss = 8.4441970102489e-05\n",
      "Loss = 8.270802936749533e-05\n",
      "Loss = 8.100852573988959e-05\n",
      "Loss = 7.934416498756036e-05\n",
      "Loss = 7.771402306389064e-05\n",
      "Loss = 7.61186020099558e-05\n",
      "Loss = 7.455483137164265e-05\n",
      "Loss = 7.302212907234207e-05\n",
      "Loss = 7.152217585826293e-05\n",
      "Loss = 7.005393854342401e-05\n",
      "Loss = 6.861505244160071e-05\n",
      "Loss = 6.720594683429226e-05\n",
      "Loss = 6.582543574040756e-05\n",
      "Loss = 6.447268242482096e-05\n",
      "Loss = 6.314973143162206e-05\n",
      "Loss = 6.185259553603828e-05\n",
      "Loss = 6.058132930775173e-05\n",
      "Loss = 5.9338079154258594e-05\n",
      "Loss = 5.8119137975154445e-05\n",
      "Loss = 5.692481863661669e-05\n",
      "Loss = 5.575575414695777e-05\n",
      "Loss = 5.4611573432339355e-05\n",
      "Loss = 5.348913327907212e-05\n",
      "Loss = 5.239024176262319e-05\n",
      "Loss = 5.131444413564168e-05\n",
      "Loss = 5.0259190174983814e-05\n",
      "Loss = 4.9226771807298064e-05\n",
      "Loss = 4.821586117031984e-05\n",
      "Loss = 4.722519952338189e-05\n",
      "Loss = 4.625518704415299e-05\n",
      "Loss = 4.530517981038429e-05\n",
      "Loss = 4.4375494326232e-05\n",
      "Loss = 4.346346759120934e-05\n",
      "Loss = 4.2570300138322636e-05\n",
      "Loss = 4.169682506471872e-05\n",
      "Loss = 4.08408377552405e-05\n",
      "Loss = 4.000169792561792e-05\n",
      "Loss = 3.917960202670656e-05\n",
      "Loss = 3.837516123894602e-05\n",
      "Loss = 3.7586436519632116e-05\n",
      "Loss = 3.6814442864852026e-05\n",
      "Loss = 3.605845631682314e-05\n",
      "tensor([[18.9825]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the model\n",
    "model = nn.Sequential(nn.Linear(1, 1))\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Prepare data\n",
    "xs = torch.tensor([[-1.0], [0.0], [1.0], [2.0], [3.0], [4.0]], dtype=torch.float32)\n",
    "ys = torch.tensor([[-3.0], [-1.0], [1.0], [3.0], [5.0], [7.0]], dtype=torch.float32)\n",
    "\n",
    "# Training loop\n",
    "for _ in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(xs)\n",
    "    loss = criterion(outputs, ys)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(\"Loss = \" + str(loss.item()))\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    prediction = model(torch.tensor([[10.0]], dtype=torch.float32))\n",
    "    print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IQMjYiLzcr0P",
    "outputId": "991a17a7-c2ff-427b-ccee-7a959431a97b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [[1.9970648]]\n",
      "Bias: [-0.9908999]\n"
     ]
    }
   ],
   "source": [
    "# Access the first (and only) layer in the sequential model\n",
    "layer = model[0]\n",
    "\n",
    "# Get weights and bias\n",
    "weights = layer.weight.data.numpy()\n",
    "bias = layer.bias.data.numpy()\n",
    "\n",
    "print(\"Weights:\", weights)\n",
    "print(\"Bias:\", bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
